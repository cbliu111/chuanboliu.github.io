---
title: "FlexOlmo: distributed training, routed inference"
date: 2026-01-04
categories:
  - blog
tags:
  - algorithm
  - MoE
math: true
---

[FlexOlmo: Open Language Models for Flexible Data Use], published by Ai2.

- **Core problem**: massive data for training and legal/privacy restrictions for localized data that is “closed” (e.g., medical records).
    
- **FlexOlmo solution**:
    
    - Decentralized training: Allowing data owners to train their own “expert” modules on private data locally, without ever sharing the raw text.
        
    - Flexible inference: These independent experts are then merged into a single model. Users can dynamically “opt-in” or “opt-out” of specific data sources at runtime. e.g. you could unplug the “Reddit expert” or the “Copyrighted Book expert” from the model instantly without retraining it.
        
- **Technical novelties**: fine-tune expert layers + fine-tune router
    
    - Independent “coordinated” training
        
        - The problem: how to merge two independent module experts. Usually, if you train two parts of a neural network separately, they don’t work together when you combine them.
            
        - The innovation: FlexOlmo uses a “public model” as a frozen anchor. When a data owner trains their private expert, they freeze the public model layers and only train their expert to work in coordination with that frozen public anchor. This ensures that experts trained by completely different companiew on different data will still speak the same “language” when merged later.
            
    - Domain-informed router (router-free merging)
        
        - The problem: In a mixture-of-experts (MoE) model, a “router” network decides which expert handles which word. This router usually needs to be trained on *all* the data at once to learn who is best at what.
            
        - The innovation: FlexOlmo eliminates the need for joint training of the router.
            
            - They initialize the router using domain embeddings (vectors that represent the “topic” of the private data).
                
            - They fine-tune these router embeddings locally.
                
            - At inference time, they simply concatenate these embeddings. The model effectively knows “This sentence looks like Math, send it to the Math expert,” even though the Math expert and the router never saw the other data during training.
                
    - True data opt-out: unlearning by removal
        
        - The innovation: Because the data is isolated in specific expert modules (feed forward networks), removing a dataset from the model is as simple as deleting that specific expert. This provides a much stronger guarantee of “unlearning” or copyright compliance than current methods, which try to “wash” data out of a dense neural network.
            
- **The “FlexMix” benchmark**
    
    - To test FlexOlmo, the authors created FlexMix, a realistic simulation of a data ecosystem containing a “public mix” (safe web data) and 7 “closed” domains (including Reddit, restricted code, copyrighted books, and medical text).
        
    - Results: FlexOlmo outperformed the base public model by 41% and beat other model-merging techniques (such as Model Soups) by 10%, proving that you can build a powerful model without ever centralizing the data.
        
- **My comments**:
    
    - Merging different experts into the public model is like pushing a github branch to the remote repository where all knowledge is held in the cloud.
        
    - Is it possible to “re-enginer” the data from the private expert?
        
    - Why merge the module expert into a single model? Most application areas may be fine with a domain expert model.
        
    - What is the cost/expertise of training module experts on private data? Isn’t this solution merely a distributed training where the local private expert fine-tunning the remote public one?
        
    - If we know how to interprete neural circuits, we can do better to remove specific knowledge, instead of domain knowledge

[FlexOlmo: Open Language Models for Flexible Data Use]: https://arxiv.org/abs/2507.07024
