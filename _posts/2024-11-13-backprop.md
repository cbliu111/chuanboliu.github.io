---
title: "Backpropagation"
date: 2024-11-13
categories:
  - blog
tags:
  - algorithm
  - training
math: true
---

Backprop is efficient since the propagation of errors only requires the same amount of computation as is needed for a forward propagation to pass through the network. 
The key insight behind the backprop algorithm is the error signals can be computed recursively via the chain rule, rather than reinforcement learning (injecting noise and observing the outcomes).
Given the loss function $\mathcal{L} = E(\mathbf{a}\_{L} - \mathbf{t})$, where the row vector $\mathbf{a}\_l = \mathbf{W}\_{l} \mathbf{h}\_{l-1}$ represents the summation of input neuronal activities of layer $l$, and $\mathbf{h}\_{l} = \mathbf{f}(\mathbf{a}\_{l})$ is the activities from layer $l$, and $\mathbf{t}$ is the target vector. 
We immediately have $\frac{\partial \mathbf{a}\_l}{\partial \mathbf{W}\_l} = \mathbf{h}^T_{l-1}$, and $\frac{\partial \mathbf{a}\_{l+1}}{\partial \mathbf{a}\_l} = \mathbf{W}\_{l+1} \odot \mathbf{f}'(\mathbf{a}\_l)$, with $\odot$ the element-wise multiplication. 
The updating rule is 

$\Delta \mathbf{W}\_l = - \eta \frac{\partial \mathcal{L}}{\partial \mathbf{W}} = - \eta \frac{\partial \mathcal{L}}{\partial \mathbf{a}\_L} \cdot \cdots \cdot \frac{\partial \mathbf{a}\_{l+1}}{\partial \mathbf{a}\_l} \cdot \frac{\partial \mathbf{a}\_l}{\partial \mathbf{W}\_l} = -\eta \mathbf{\delta}\_l \mathbf{h}^T_{l-1}$

The vector differentiation matrix is defined as $\left(\frac{\partial A}{\partial B}\right)\_{ij} = \frac{\partial A_i}{\partial B_j}$, and the dot-product of vector differentiation matrix is a summation of all connection paths $\left(\frac{\partial A}{\partial B} \cdot \frac{\partial B}{\partial C}\right)\_{ij} = \sum_k \frac{\partial A_i}{\partial B_k} \frac{\partial B_k}{\partial C_j} $. 
The propagate error is $\mathbf{\delta}\_l = \frac{\partial \mathcal{L}}{\partial \mathbf{a}\_L} \cdot \cdots \cdot \frac{\partial \mathbf{a}\_{l+1}}{\partial \mathbf{a}\_l}$, which can be calculated recursively $\mathbf{\delta}\_l = \mathbf{\delta}\_{l+1} \cdot \frac{\partial \mathbf{a}\_{l+1}}{\partial \mathbf{a}\_l}= (\mathbf{W}^T_{l+1}\mathbf{\delta}\_{l+1}) \odot \mathbf{f}'(\mathbf{a}\_l) = \mathbf{e}\_l \odot \mathbf{f}'(\mathbf{a}\_l)$.

And the updating rule is a reformulation of the local Hebbian-like rule $\Delta \mathbf{W}\_l = -\eta (\mathbf{e}\_l \odot \mathbf{f}'(\mathbf{a}\_l)) \mathbf{h}^T_{l-1}$.
In this form, $\mathbf{e}\_l = \mathbf{W}^T_{l+1}\mathbf{\delta}\_{l+1}$ is acting like $\mathbf{a}\_l = \mathbf{W}\_l \mathbf{h}\_{l-1}$, and $\mathbf{\delta}\_l = \mathbf{e}\_l \odot \mathbf{f}'(\mathbf{a}\_l)$ is acting like $\mathbf{h}\_l = \mathbf{f}(\mathbf{a}\_l)$. 

Backprop is efficient, since the computational time complexity for the backward passage is on the same order of the forward passage {lillicrapBackpropagationBrain2020}. 
The problem of backprop lies in the exact correspondence of the forward passage and the backward passage. 
The updating of the weights demands the knowledge of all the forward computational paths. 
This exact correspondence of forward and backward passage has another side effect: the trained network lost its plasticity {dohareLossPlasticityDeep2024}. 
This is because for every new data, the network will attempt to adjust all the computational paths that lead to a divergence to the training target. 
The change of the weights for the entire computational path may influence the prediction of the old knowledge. 
Moreover, for output neurons that are not deviated from the target, there are no weight adjustment at all. 
It is argued that in order to minimize interference, a compensation of weight adjustment should be performed for neurons that are not deviate from the target {songInferringNeuralActivity2024}. 
The direct result of this loss of plasticity is the catastrophic forgetting of the old knowledge when training with new dataset. 

Another issue about backprop is the demand of a fixed form of hand-designed loss function that is preset a priori before learning. 
This loss function is essential and vital important for training, because the weight gradient is completely dependent on its form. 
This demand, together with the global updating strategy of the backprop, completely eliminate the possibility of a modularity design of neural network. 
Some alternative learning strategy, such as the Joint Embedding Predictive Architecture (JEPA) {assranSelfSupervisedLearningImages2023}, attempt to restore the modularity structure of the brain. 
However, the learning strategy is still based on backprop with a predefined loss function. 
A predefined loss function, which is highly task specific, can hardly produce general purpose intelligence. 

